{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"factoryName": {
			"type": "string",
			"metadata": "Data Factory name",
			"defaultValue": "adfRealTimeCase"
		}
	},
	"variables": {
		"factoryId": "[concat('Microsoft.DataFactory/factories/', parameters('factoryName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('factoryName'), '/dataflow2RemoveDuplicates')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_flow_input1",
								"type": "DatasetReference"
							},
							"name": "emp1"
						},
						{
							"dataset": {
								"referenceName": "ds_low_input2",
								"type": "DatasetReference"
							},
							"name": "emp2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sql_flow_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "union1"
						},
						{
							"name": "aggregate1"
						},
						{
							"name": "sort1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as string,",
						"          ename as string,",
						"          sal as string,",
						"          dept as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp1",
						"source(output(",
						"          empid as string,",
						"          ename as string,",
						"          sal as string,",
						"          dept as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> emp2",
						"emp1, emp2 union(byName: true)~> union1",
						"union1 aggregate(groupBy(empid),",
						"     each(match(name!='empid'), $$ = first($$))) ~> aggregate1",
						"aggregate1 sort(asc(empid, true)) ~> sort1",
						"sort1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     deletable:false,",
						"     insertable:true,",
						"     updateable:false,",
						"     upsertable:false,",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError') ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow4RunningTotal')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_dataflow_empRunningTot_input",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_Dataflow_RunningTotal_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "window1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          id as string,",
						"          name as string,",
						"          sal as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 window(asc(sal, true),",
						"     RunningTotalSal = sum(toInteger(sal))) ~> window1",
						"window1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          Column_1 as string,",
						"          Column_2 as string",
						"     ),",
						"     partitionFileNames:['RunningTotalEmp.csv'],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow5pipelineLog')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_dataflow_dummylog_input",
								"type": "DatasetReference"
							},
							"name": "DummySource"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_dtaflow_log_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"parameters{",
						"     ADFname as string ('default'),",
						"     PipelineName as string ('default'),",
						"     TriggetTime as string ('default'),",
						"     LogFileName as string ('default')",
						"}",
						"source(output(",
						"          dummyheader as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> DummySource",
						"DummySource derive(AdfName = $ADFname,",
						"          PipelineName = $PipelineName,",
						"          Runtime = $TriggetTime) ~> derivedColumn1",
						"derivedColumn1 select(mapColumn(",
						"          AdfName,",
						"          PipelineName,",
						"          Runtime",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:[($LogFileName)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     mapColumn(",
						"          AdfName,",
						"          PipelineName,",
						"          Runtime",
						"     ),",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow5pipelineLog_Append')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_dataflow_dummylog_input",
								"type": "DatasetReference"
							},
							"name": "DummySource"
						},
						{
							"dataset": {
								"referenceName": "ds_dataflow_log_append",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_dtaflow_log_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "select1"
						},
						{
							"name": "union1"
						}
					],
					"scriptLines": [
						"parameters{",
						"     ADFname as string,",
						"     PipelineName as string,",
						"     TriggetTime as string,",
						"     LogFileName as string",
						"}",
						"source(output(",
						"          dummyheader as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> DummySource",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"DummySource derive(AdfName = $ADFname,",
						"          PipelineName = $PipelineName,",
						"          Runtime = $TriggetTime) ~> derivedColumn1",
						"derivedColumn1 select(mapColumn(",
						"          AdfName,",
						"          PipelineName,",
						"          Runtime",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1, source1 union(byName: true)~> union1",
						"union1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:[($LogFileName)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow6Pipelinelog1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_dataflow_log_input1",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_dataflow_log_output1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "select1"
						}
					],
					"scriptLines": [
						"parameters{",
						"     ADFName as string,",
						"     pipelineName as string,",
						"     runtime as string,",
						"     filename as string",
						"}",
						"source(output(",
						"          dummyheader as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 derive(ADFName = $ADFName,",
						"          Pipelinename = $pipelineName,",
						"          RunTime = $runtime) ~> derivedColumn1",
						"derivedColumn1 select(mapColumn(",
						"          ADFName,",
						"          Pipelinename,",
						"          RunTime",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:[($filename)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow6Pipelinelog_append1')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_dataflow_log_input1",
								"type": "DatasetReference"
							},
							"name": "source1"
						},
						{
							"dataset": {
								"referenceName": "ds_dataflow_log_output1",
								"type": "DatasetReference"
							},
							"name": "source2"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_dataflow_log_output1",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "derivedColumn1"
						},
						{
							"name": "select1"
						},
						{
							"name": "union1"
						}
					],
					"scriptLines": [
						"parameters{",
						"     ADFName as string,",
						"     pipelineName as string,",
						"     runtime as string,",
						"     filename as string",
						"}",
						"source(output(",
						"          dummyheader as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source2",
						"source1 derive(ADFName = $ADFName,",
						"          Pipelinename = $pipelineName,",
						"          RunTime = $runtime) ~> derivedColumn1",
						"derivedColumn1 select(mapColumn(",
						"          ADFName,",
						"          Pipelinename,",
						"          RunTime",
						"     ),",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true) ~> select1",
						"select1, source2 union(byName: true)~> union1",
						"union1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     partitionFileNames:[($filename)],",
						"     umask: 0022,",
						"     preCommands: [],",
						"     postCommands: [],",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     partitionBy('hash', 1)) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/dataflow7SCD')]",
			"type": "Microsoft.DataFactory/factories/dataflows",
			"apiVersion": "2018-06-01",
			"properties": {
				"type": "MappingDataFlow",
				"typeProperties": {
					"sources": [
						{
							"dataset": {
								"referenceName": "ds_dataflow_empscd_input",
								"type": "DatasetReference"
							},
							"name": "source1"
						}
					],
					"sinks": [
						{
							"dataset": {
								"referenceName": "ds_sql_EmpScd_output",
								"type": "DatasetReference"
							},
							"name": "sink1"
						}
					],
					"transformations": [
						{
							"name": "alterRow1"
						}
					],
					"scriptLines": [
						"source(output(",
						"          empid as integer,",
						"          ename as string,",
						"          sal as integer,",
						"          dept as string",
						"     ),",
						"     allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     ignoreNoFilesFound: false) ~> source1",
						"source1 alterRow(upsertIf(1==1)) ~> alterRow1",
						"alterRow1 sink(allowSchemaDrift: true,",
						"     validateSchema: false,",
						"     input(",
						"          empid as integer,",
						"          ename as string,",
						"          Sal as integer,",
						"          Dept as string",
						"     ),",
						"     deletable:false,",
						"     insertable:false,",
						"     updateable:false,",
						"     upsertable:true,",
						"     keys:['empid'],",
						"     format: 'table',",
						"     skipDuplicateMapInputs: true,",
						"     skipDuplicateMapOutputs: true,",
						"     errorHandlingOption: 'stopOnFirstError',",
						"     mapColumn(",
						"          empid,",
						"          ename,",
						"          Sal = sal,",
						"          Dept = dept",
						"     )) ~> sink1"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline10dataFlowlog1')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Wait1",
						"type": "Wait",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"waitTimeInSeconds": 1
						}
					},
					{
						"name": "Set variable1",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Wait1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "filename",
							"value": {
								"value": "@concat(formatDateTime(utcnow(),'yyyy-MM-dd'),'_log.csv')",
								"type": "Expression"
							}
						}
					},
					{
						"name": "Get Metadata1",
						"type": "GetMetadata",
						"dependsOn": [
							{
								"activity": "Set variable1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "ds_dataflow_log_output1",
								"type": "DatasetReference",
								"parameters": {}
							},
							"fieldList": [
								"exists"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "If Condition1",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@activity('Get Metadata1').output.exists",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Data flow1",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "dataflow6Pipelinelog1",
											"type": "DataFlowReference",
											"parameters": {
												"ADFName": {
													"value": "'@{pipeline().DataFactory}'",
													"type": "Expression"
												},
												"pipelineName": {
													"value": "'@{pipeline().Pipeline}'",
													"type": "Expression"
												},
												"runtime": {
													"value": "'@{pipeline().TriggerTime}'",
													"type": "Expression"
												},
												"filename": {
													"value": "'@{variables('filename')}'",
													"type": "Expression"
												}
											},
											"datasetParameters": {
												"source1": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							],
							"ifTrueActivities": [
								{
									"name": "Data flowappend",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "dataflow6Pipelinelog_append1",
											"type": "DataFlowReference",
											"parameters": {
												"ADFName": {
													"value": "'@{pipeline().DataFactory}'",
													"type": "Expression"
												},
												"pipelineName": {
													"value": "'@{pipeline().Pipeline}'",
													"type": "Expression"
												},
												"runtime": {
													"value": "'@{pipeline().TriggerTime}'",
													"type": "Expression"
												},
												"filename": {
													"value": "'@{variables('filename')}'",
													"type": "Expression"
												}
											},
											"datasetParameters": {
												"source1": {},
												"source2": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"variables": {
					"filename": {
						"type": "String"
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow6Pipelinelog1')]",
				"[concat(variables('factoryId'), '/dataflows/dataflow6Pipelinelog_append1')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline11SCD')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow7SCD",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow7SCD')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline1handlingErrorData')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"description": "Fetching data from source and based on data correction ingesing it intoSQL good/bad tables",
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow1ErrHandling",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"SalesIndia": {},
									"sink1": {},
									"sink2": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline7DuplicateRemoval')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow2RemoveDuplicates",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"emp1": {},
									"emp2": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow2RemoveDuplicates')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline8RunningTotal')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Data flow1",
						"type": "ExecuteDataFlow",
						"dependsOn": [],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataflow": {
								"referenceName": "dataflow4RunningTotal",
								"type": "DataFlowReference",
								"parameters": {},
								"datasetParameters": {
									"source1": {},
									"sink1": {}
								}
							},
							"staging": {},
							"compute": {
								"coreCount": 8,
								"computeType": "General"
							},
							"traceLevel": "Fine"
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow4RunningTotal')]"
			]
		},
		{
			"name": "[concat(parameters('factoryName'), '/pipeline9dataFlowlog')]",
			"type": "Microsoft.DataFactory/factories/pipelines",
			"apiVersion": "2018-06-01",
			"properties": {
				"activities": [
					{
						"name": "Wait1",
						"type": "Wait",
						"dependsOn": [],
						"userProperties": [],
						"typeProperties": {
							"waitTimeInSeconds": 1
						}
					},
					{
						"name": "Set variable1",
						"type": "SetVariable",
						"dependsOn": [
							{
								"activity": "Wait1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"variableName": "File",
							"value": {
								"value": "@concat(formatDateTime(utcNow(),'yyyy-MM-dd'),'_log.csv')",
								"type": "Expression"
							}
						}
					},
					{
						"name": "Get Metadata1",
						"type": "GetMetadata",
						"dependsOn": [
							{
								"activity": "Set variable1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"policy": {
							"timeout": "0.12:00:00",
							"retry": 0,
							"retryIntervalInSeconds": 30,
							"secureOutput": false,
							"secureInput": false
						},
						"userProperties": [],
						"typeProperties": {
							"dataset": {
								"referenceName": "ds_dataflow_log_append",
								"type": "DatasetReference",
								"parameters": {
									"dfilename": {
										"value": "@variables('File')",
										"type": "Expression"
									}
								}
							},
							"fieldList": [
								"exists"
							],
							"storeSettings": {
								"type": "AzureBlobFSReadSettings",
								"recursive": true,
								"enablePartitionDiscovery": false
							},
							"formatSettings": {
								"type": "DelimitedTextReadSettings"
							}
						}
					},
					{
						"name": "If Condition1",
						"type": "IfCondition",
						"dependsOn": [
							{
								"activity": "Get Metadata1",
								"dependencyConditions": [
									"Succeeded"
								]
							}
						],
						"userProperties": [],
						"typeProperties": {
							"expression": {
								"value": "@activity('Get Metadata1').output.exists",
								"type": "Expression"
							},
							"ifFalseActivities": [
								{
									"name": "Data flowlog",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "dataflow5pipelineLog",
											"type": "DataFlowReference",
											"parameters": {
												"ADFname": {
													"value": "'@{pipeline().DataFactory}'",
													"type": "Expression"
												},
												"PipelineName": {
													"value": "'@{pipeline().Pipeline}'",
													"type": "Expression"
												},
												"TriggetTime": {
													"value": "'@{pipeline().TriggerTime}'",
													"type": "Expression"
												},
												"LogFileName": {
													"value": "'@{variables('File')}'",
													"type": "Expression"
												}
											},
											"datasetParameters": {
												"DummySource": {},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							],
							"ifTrueActivities": [
								{
									"name": "Data flowAppend",
									"type": "ExecuteDataFlow",
									"dependsOn": [],
									"policy": {
										"timeout": "0.12:00:00",
										"retry": 0,
										"retryIntervalInSeconds": 30,
										"secureOutput": false,
										"secureInput": false
									},
									"userProperties": [],
									"typeProperties": {
										"dataflow": {
											"referenceName": "dataflow5pipelineLog_Append",
											"type": "DataFlowReference",
											"parameters": {
												"ADFname": {
													"value": "'@{pipeline().DataFactory}'",
													"type": "Expression"
												},
												"PipelineName": {
													"value": "'@{pipeline().Pipeline}'",
													"type": "Expression"
												},
												"TriggetTime": {
													"value": "'@{pipeline().TriggerTime}'",
													"type": "Expression"
												},
												"LogFileName": {
													"value": "'@{variables('File')}'",
													"type": "Expression"
												}
											},
											"datasetParameters": {
												"DummySource": {},
												"source1": {
													"dfilename": {
														"value": "@variables('File')",
														"type": "Expression"
													}
												},
												"sink1": {}
											}
										},
										"staging": {},
										"compute": {
											"coreCount": 8,
											"computeType": "General"
										},
										"traceLevel": "Fine"
									}
								}
							]
						}
					}
				],
				"policy": {
					"elapsedTimeMetric": {},
					"cancelAfter": {}
				},
				"variables": {
					"File": {
						"type": "String"
					}
				},
				"annotations": []
			},
			"dependsOn": [
				"[concat(variables('factoryId'), '/dataflows/dataflow5pipelineLog')]",
				"[concat(variables('factoryId'), '/dataflows/dataflow5pipelineLog_Append')]"
			]
		}
	]
}